{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using zero padding!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, confusion_matrix, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import datatable as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import UQ_toolbox as uq\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 3\n",
      "GPU 0: NVIDIA RTX A6000\n",
      "GPU 1: NVIDIA RTX A6000\n",
      "GPU 2: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(\"Number of GPUs available:\", num_gpus)\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "except Exception as e:\n",
    "    print(\"Error while checking GPUs:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your CNN model\n",
    "class simpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simpleNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout_conv = nn.Dropout(0.3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(32*12*12, 64)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x= self.dropout_conv(x)\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = self.dropout_conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, shape, img_name = sample['image'], sample['shape'], sample['name']\n",
    "        if shape=='Round':\n",
    "            shape=0\n",
    "        elif shape=='Irregular':\n",
    "            shape=1\n",
    "        elif shape=='Ambiguous':\n",
    "            shape=2\n",
    "        return {'image': torch.from_numpy(image).unsqueeze(0),\n",
    "                'shape': torch.from_numpy(np.asarray(shape)),\n",
    "                'name': img_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    def __call__(self, sample):\n",
    "        image, shape, img_name = sample['image'], sample['shape'], sample['name']\n",
    "        norm = transforms.Normalize(mean=self.mean, std=self.std)\n",
    "        return {'image': norm(image.float()),\n",
    "                'shape': shape,            \n",
    "                'name': img_name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "model_paths = ['model_shape_0_augmented.pt', 'model_shape_1_augmented.pt', 'model_shape_2_augmented.pt', 'model_shape_3_augmented.pt', 'model_shape_4_augmented.pt']\n",
    "models_list = []\n",
    "\n",
    "for path in model_paths:\n",
    "    model = simpleNet()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    models_list.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AxialCutsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_shape, transform=None, for_trainning=False, mean=False, std=False, downsample=False):\n",
    "        self.data = data_shape\n",
    "        self.transform=transform\n",
    "        self.for_trainning = for_trainning\n",
    "        self.mean= mean\n",
    "        self.std = std\n",
    "        self.downsample = downsample\n",
    "\n",
    "        if self.downsample:\n",
    "            df_majority = self.data[self.data.iloc[:, 1]=='Irregular']\n",
    "            df_majority_downsampled = resample(df_majority, replace=False, n_samples=1200, random_state=125)\n",
    "            self.data = pd.concat((self.data[self.data['Shape'] != 'Irregular'], df_majority_downsampled))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data.iloc[:, 0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_name = self.data.iloc[idx, 0]\n",
    "        image = io.imread(img_name)\n",
    "        shape = self.data.iloc[idx, 1]\n",
    "        sample = {'image': image, 'shape': shape, 'name':img_name}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for evaluation metrics\n",
    "def accuracy(outputs, labels):\n",
    "    preds = outputs > 0.5 \n",
    "    return accuracy_score(labels, preds)\n",
    "\n",
    "def f1(outputs, labels):\n",
    "    preds = outputs > 0.5\n",
    "    return f1_score(labels, preds, average='binary')\n",
    "\n",
    "def calculate_sensitivity(outputs, labels):\n",
    "    preds = outputs > 0.5\n",
    "    return recall_score(labels, preds, average='binary')\n",
    "\n",
    "def roc_auc(outputs, labels):\n",
    "    probs = outputs\n",
    "    return roc_auc_score(labels, probs)\n",
    "\n",
    "def compute_confusion_matrix(outputs, labels):\n",
    "    preds = outputs > 0.5\n",
    "    return confusion_matrix(labels, preds)\n",
    "\n",
    "def calculate_specificity(cm):\n",
    "    TN = cm[0, 0]  # True negatives\n",
    "    FP = cm[0, 1]  # False positives\n",
    "    return TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_confusion_matrix(cm):\n",
    "    # Define class names\n",
    "    class_names = ['Round', 'Irregular']\n",
    "    \n",
    "    # Create a DataFrame for better visualization\n",
    "    df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "    \n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(df_cm, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={\"size\": 20})\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_val_metrics(all_preds, all_labels):\n",
    "\n",
    "    # Compute evaluation metrics\n",
    "    acc = accuracy(all_preds, all_labels)\n",
    "    f1_result = f1(all_preds, all_labels)\n",
    "    roc_auc_result = roc_auc(all_preds, all_labels)\n",
    "    cm = compute_confusion_matrix(all_preds, all_labels)\n",
    "    display_confusion_matrix(cm)\n",
    "    sensitivity_value = calculate_sensitivity(all_preds, all_labels)\n",
    "    specificity_value = calculate_specificity(cm)\n",
    "\n",
    "    print('Accuracy: {:.6f} \\tF1 Score: {:.6f} \\tROC AUC: {:.6f} \\tSpecificity: {:.6f} \\tSensitivity: {:.6f}'.format(\n",
    "        acc, f1_result, roc_auc_result, specificity_value, sensitivity_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make predictions\n",
    "def predict(models, image):\n",
    "    image = image.to(device)\n",
    "    predictions = [model(image).cpu().detach().numpy() for model in models]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tumor_predictions_with_percentages(data, shape_df):\n",
    "\n",
    "    # Process and aggregate data for the bar plot\n",
    "    tumor_data = {}\n",
    "    \n",
    "    for entry in data:\n",
    "        img_name = entry['img_name']\n",
    "        predicted_class = entry['predicted_class']\n",
    "        # Extract patient (tumor) number and cut number from the image name\n",
    "        tumor_id, cut_id_with_ext = img_name.split('/')[-1].split('_')[:2]\n",
    "        cut_id = cut_id_with_ext.split('.')[0]  # Remove .png extension\n",
    "        \n",
    "        if tumor_id not in tumor_data:\n",
    "            tumor_data[tumor_id] = []\n",
    "        \n",
    "        # Add predicted class (0 for round, 1 for irregular) to tumor's list\n",
    "        tumor_data[tumor_id].append((int(cut_id), predicted_class))\n",
    "    \n",
    "    # Sort cuts by their axial number within each tumor\n",
    "    for tumor_id in tumor_data:\n",
    "        tumor_data[tumor_id].sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Create bar plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 10))\n",
    "    \n",
    "    # For each tumor, create a row of colored bars based on the axial cut predictions\n",
    "    y_positions = np.arange(len(tumor_data))\n",
    "    \n",
    "    for i, (tumor_id, cuts) in enumerate(sorted(tumor_data.items())):\n",
    "     \n",
    "        # Extract cut numbers and predicted classes\n",
    "        cut_ids, predicted_classes = zip(*cuts)\n",
    "        \n",
    "        # Create a color map: red for 'Round' (class 0) and blue for 'Irregular' (class 1)\n",
    "        colors = ['red' if pred == 0 else 'blue' for pred in predicted_classes]\n",
    "        \n",
    "        # Initialize variables to keep track of blocks of the same color\n",
    "        current_color = colors[0]\n",
    "        block_start = cut_ids[0]\n",
    "        block_count = 1\n",
    "        \n",
    "        total_cuts = len(cuts)\n",
    "        \n",
    "        for j in range(1, total_cuts):\n",
    "            if colors[j] == current_color:\n",
    "                # Continue the current block\n",
    "                block_count += 1\n",
    "            else:\n",
    "                # End the current block, plot it\n",
    "                ax.barh(i, block_count, left=block_start, height=0.8, color=current_color)\n",
    "                \n",
    "                # Calculate the percentage for the block\n",
    "                percentage = (block_count / total_cuts) * 100\n",
    "                \n",
    "                # Add the percentage as text in the middle of the block\n",
    "                ax.text(block_start + block_count / 2, i, f'{percentage:.1f}%', va='center', ha='center', color='white')\n",
    "                \n",
    "                # Start a new block\n",
    "                current_color = colors[j]\n",
    "                block_start = cut_ids[j]\n",
    "                block_count = 1\n",
    "        \n",
    "        # Plot the final block\n",
    "        ax.barh(i, block_count, left=block_start, height=0.8, color=current_color)\n",
    "        percentage = (block_count / total_cuts) * 100\n",
    "        ax.text(block_start + block_count / 2, i, f'{percentage:.1f}%', va='center', ha='center', color='white')\n",
    "        \n",
    "        # Get the shape from the dataframe based on the tumor ID\n",
    "        try:\n",
    "            shape_label = shape_df.loc[shape_df['Record_ID'] == int(tumor_id), 'Shape.1'].values[0]\n",
    "        except IndexError:\n",
    "            shape_label = 'Unknown'  # Assign a default value if not found\n",
    "\n",
    "        # Add the shape label as text at the end of the bar\n",
    "        ax.text(max(cut_ids) + 1, i, shape_label, va='center')\n",
    "    \n",
    "    ax.set_xlabel('Axial Cuts')\n",
    "    ax.set_ylabel('Tumors')\n",
    "    ax.set_title('Tumor Axial Cut Predictions with Percentages and Shape Labels')\n",
    "    ax.set_yticks(y_positions)\n",
    "    ax.set_yticklabels(sorted(tumor_data.keys()))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_tumors_by_contingent_blocks_with_sorting(data, shape_df, threshold=60):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # Process and aggregate data for each tumor\n",
    "    tumor_data = {}\n",
    "    \n",
    "    for entry in data:\n",
    "        img_name = entry['img_name']\n",
    "        predicted_class = entry['predicted_class']\n",
    "        \n",
    "        # Extract patient (tumor) number and cut number from the image name\n",
    "        tumor_id, cut_id_with_ext = img_name.split('/')[-1].split('_')[:2]\n",
    "        cut_id = int(cut_id_with_ext.split('.')[0])  # Remove .png extension and convert to integer for sorting\n",
    "        \n",
    "        if tumor_id not in tumor_data:\n",
    "            tumor_data[tumor_id] = []\n",
    "        \n",
    "        # Append both cut_id and predicted class to ensure sorting\n",
    "        tumor_data[tumor_id].append((cut_id, predicted_class))\n",
    "    \n",
    "    # Classify each tumor based on the largest contiguous block of \"Round\" cuts\n",
    "    for tumor_id, cuts in tumor_data.items():\n",
    "        # Sort cuts by cut_id to ensure the correct sequence\n",
    "        cuts_sorted = sorted(cuts, key=lambda x: x[0])  # Sort by cut_id\n",
    "        \n",
    "        # Extract only the predicted classes from sorted data\n",
    "        predicted_classes_sorted = [pred_class for _, pred_class in cuts_sorted]\n",
    "        \n",
    "        #print(f\"Processing tumor ID: {tumor_id}\")\n",
    "        \n",
    "        # Find the true label from the shape_df dataframe ('Shape.1' column)\n",
    "        try:\n",
    "            shape_label = shape_df.loc[shape_df['Record_ID'] == int(tumor_id), 'Shape.1'].values[0]\n",
    "            true_label = 0 if shape_label == 'Round' else 1  # Convert 'Round' to 0, 'Irregular' to 1\n",
    "            #print(f\"True label (from Shape.1): {shape_label}, Converted to: {true_label}\")\n",
    "        except IndexError:\n",
    "            #print(f\"Tumor ID {tumor_id} not found in shape_df!\")\n",
    "            continue  # Skip if tumor_id not found in shape_df\n",
    "        \n",
    "        # Calculate the largest contiguous block of \"Round\" (class 0) cuts\n",
    "        max_round_block = 0\n",
    "        current_round_block = 0\n",
    "        total_cuts = len(predicted_classes_sorted)\n",
    "        \n",
    "        for pred_class in predicted_classes_sorted:\n",
    "            if pred_class == 0:\n",
    "                current_round_block += 1\n",
    "            else:\n",
    "                current_round_block = 0\n",
    "            max_round_block = max(max_round_block, current_round_block)\n",
    "        \n",
    "        round_percentage = (max_round_block / total_cuts) * 100\n",
    "        #print(f\"Largest contiguous round block: {max_round_block} out of {total_cuts} cuts ({round_percentage:.1f}%)\")\n",
    "        \n",
    "        # Apply the classification rule: Round if any block is >= threshold, else Irregular\n",
    "        predicted_label = 0 if round_percentage >= threshold else 1\n",
    "        #print(f\"Predicted label based on threshold: {predicted_label}\")\n",
    "        \n",
    "        # Store true and predicted labels\n",
    "        y_true.append(true_label)\n",
    "        y_pred.append(predicted_label)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Compute balanced accuracy\n",
    "    bal_acc = balanced_accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Compute sensitivity (recall for class 1, irregular)\n",
    "    sensitivity = recall_score(y_true, y_pred, pos_label=1)\n",
    "    \n",
    "    # Compute specificity (recall for class 0, round)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)\n",
    "    \n",
    "    return cm, bal_acc, sensitivity, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean = 87.42158495776914\n",
    "std = 29.82248099334633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 87.42158495776914\n",
    "std = 29.82248099334633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '/mnt/data/psteinmetz/neotex/data_CNN/model_evaluation/evaluation_IRM_villes/'\n",
    "data = pd.concat(\n",
    "    (\n",
    "        pd.DataFrame(glob.glob(f'{images_path}*/*png')),\n",
    "        pd.DataFrame(\n",
    "            [x.split('/')[-1][:-4] for x in glob.glob(f'{images_path}*/*png')]\n",
    "        ),\n",
    "        pd.DataFrame(\n",
    "            [k.split('/')[-2] for k in glob.glob(f'{images_path}*/*png')]\n",
    "        ),\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "data.columns = ['Path', 'ID', 'Shape']\n",
    "data.set_index('ID', inplace=True)\n",
    "\n",
    "\n",
    "axialcuts_dataset_eval = AxialCutsDataset(data_shape=data, downsample=False)\n",
    "data_without_amb = axialcuts_dataset_eval.data[axialcuts_dataset_eval.data['Shape']!='Ambiguous']\n",
    "data_amb = axialcuts_dataset_eval.data[axialcuts_dataset_eval.data['Shape']=='Ambiguous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=mean, std=std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_amb = AxialCutsDataset(data_shape=data_without_amb, downsample=False, transform=data_transforms)\n",
    "data_amb = AxialCutsDataset(data_shape=data_amb, downsample=False, transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = DataLoader(data_without_amb, num_workers=12)\n",
    "eval_data_amb = DataLoader(data_amb, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "axialcuts_dataset_eval_all = AxialCutsDataset(data_shape=data, downsample=False, transform=data_transforms)\n",
    "eval_all_data = DataLoader(axialcuts_dataset_eval_all, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model.to(device) for model in models_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simpleNet(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout_conv): Dropout(p=0.3, inplace=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=4608, out_features=64, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ") <torch.utils.data.dataloader.DataLoader object at 0x7e74d2194490>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGPS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/psteinmetz/archive_notebooks/Documents/UQ_toolbox.py:112\u001b[0m, in \u001b[0;36mGPS\u001b[0;34m(model, test_set)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGPS\u001b[39m(model, test_set):\n\u001b[0;32m--> 112\u001b[0m     \u001b[43mgps_augment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_predictions_randaugment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/psteinmetz/archive_notebooks/Documents/gps_augment/get_predictions_randaugment.py:154\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(dataset, model, N, M, log_dir, policy, fname, data_path, batch_size, num_workers, bn_update, num_tta, no_tta, valid, silent, verbose, true_m0, fix_sign, transforms, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         num_tta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(policy)\n\u001b[1;32m    152\u001b[0m         samples_per_policy \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_tta\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_tta\n\u001b[0;32m--> 154\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_path\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m())\n\u001b[1;32m    156\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torchvision\u001b[38;5;241m.\u001b[39mdatasets, args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCIFAR10\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "uq.GPS(models[0], eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "all_results = []\n",
    "mean_pred = []\n",
    "true_labels = []\n",
    "models = [model.to(device) for model in models_list]\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    for batch in eval_data:\n",
    "        images = batch['image']\n",
    "        labels = batch['shape']\n",
    "\n",
    "        pred_probs = predict(models, images)\n",
    "        \n",
    "        # Collect the results\n",
    "        mean_pred.append(np.mean(pred_probs))\n",
    "        true_labels.append(labels.item())\n",
    "        all_results.append({\n",
    "            'true_label': labels.item(),\n",
    "            'predicted_probabilities': pred_probs,\n",
    "            'predicted_class': int(np.mean(pred_probs) > 0.5),\n",
    "            'std': np.std(pred_probs),\n",
    "            'mean': np.mean(pred_probs)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pred = [[all_results[k]['predicted_probabilities'][i].ravel() for k in range(len(all_results))] for i in range(5)]\n",
    "mean_ensembling_pred = [all_results[k]['mean'] for k in range(len(all_results))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_val_metrics(np.array(mean_pred), np.array(true_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uq.model_calibration_plot(np.array(true_labels), np.array(mean_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_idx = [k for k in range(len(all_results)) if all_results[k]['true_label'] == all_results[k]['predicted_class']]\n",
    "bad_idx = [k for k in range(len(all_results)) if all_results[k]['true_label'] != all_results[k]['predicted_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = uq.ensembling_stds_computation(models_pred)\n",
    "distances = uq.distance_to_gold_standard_computation(mean_ensembling_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uq.UQ_method_plot([stds[k] for k in good_idx], [stds[j] for j in bad_idx], 'Stds', 'Standard deviations ensembling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_with_density():\n",
    "    plt.close('all')\n",
    "    # The 5 horizontal points to be scattered\n",
    "    points = np.array([0.2, 0.45, 0.33, 0.38, 0.40, 0.35])\n",
    "    \n",
    "    # Calculate the mean and standard deviation of the points\n",
    "    mean_point = np.mean(points)\n",
    "    std_dev = np.std(points)\n",
    "    # Create a figure and axis\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    \n",
    "    # Plot the scatter points horizontally\n",
    "    plt.scatter(points, np.zeros_like(points), color='red', label='Scatter points', zorder=5)\n",
    "    \n",
    "    # Overlay the density distribution (Kernel Density Estimate)\n",
    "    sns.kdeplot(points, bw_adjust=0.8, fill=True, color='blue', label='Density Distribution', zorder=1)\n",
    "    plt.hlines(0, xmin=0, xmax=1, colors='black', linestyles='-', label='Horizontal bar', zorder=0)\n",
    "    plt.vlines(mean_point, ymin=0, ymax=3.5, colors='black', linestyles='-', label='Horizontal bar', zorder=0)\n",
    "    \n",
    "     # Plot the arrow representing the standard deviation (from mean-point Â± SD)\n",
    "    plt.annotate('', xy=(mean_point - std_dev, 3.5), xytext=(mean_point, 3.5),\n",
    "                 arrowprops=dict(facecolor='black', arrowstyle='->'))\n",
    "    \n",
    "    # Annotate the arrow with \"SD\" above it\n",
    "    plt.text(mean_point - std_dev / 2, 3.8, f'SD = {std_dev:.2f}', fontsize=10, color='black', ha='left')\n",
    "    \n",
    "    \n",
    "    # Adjusting the plot to focus only on the 0-1 axis for x\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(-0.5, 8)\n",
    "    \n",
    "    # Hide the y-axis as we're focusing on horizontal scatter\n",
    "    plt.gca().axes.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.title('Deep ensemble predictions distribution')\n",
    "    \n",
    "    # Show legend\n",
    "    #plt.legend(loc='upper left')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Run the function\n",
    "scatter_with_density()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uq.UQ_method_plot([distances[k] for k in good_idx], [distances[j] for j in bad_idx], 'min(prob; 1-prob)', 'Distance to hard labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddBatchDimension:\n",
    "    def __call__(self, image):\n",
    "        # Ensure the image is a tensor and add batch dimension\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            return image.unsqueeze(0).float()\n",
    "        raise TypeError(\"Input should be a torch Tensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandAugment(2, 9),\n",
    "        transforms.PILToTensor(),\n",
    "        AddBatchDimension(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_amb_TTA = axialcuts_dataset_eval.data[axialcuts_dataset_eval.data['Shape']!='Ambiguous']\n",
    "data_without_amb_TTA = AxialCutsDataset(data_shape=data_without_amb_TTA, downsample=False)\n",
    "eval_data_TTA = DataLoader(data_without_amb_TTA, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_results = []\n",
    "mean_pred = []\n",
    "true_labels = []\n",
    "stds_tta = []\n",
    "models = [model.to(device) for model in models_list]\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    for batch in eval_data_TTA:\n",
    "        tta_pred, std_pred = uq.TTA(tta_transform, models, batch['image'], device, nb_augmentations=50)\n",
    "        stds_tta.append(std_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uq.UQ_method_plot([stds_tta[k] for k in good_idx], [stds_tta[j] for j in bad_idx], 'Stds', 'Test Time Augmentation (n=50)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = uq.standardize_and_max(np.column_stack((stds_tta, stds, distances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.column_stack((stds_tta, stds, distances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = a.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute global mean and standard deviation\n",
    "global_mean = np.mean(combined)\n",
    "global_std_dev = np.std(combined)\n",
    "\n",
    "# Apply z-score standardization to each distribution (column)\n",
    "standardized_distributions = (a - global_mean) / global_std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum standardized value for each instance (row)\n",
    "np.mean(standardized_distributions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uq.UQ_method_plot([max_values[k] for k in good_idx], [max_values[j] for j in bad_idx], 'Combined metric', 'Combined UQ methods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_distance_to_gstd, tpr_distance_to_gstd, auc_distance_to_gstd = uq.roc_curve_UQ_method_computation([distances[k] for k in good_idx], [distances[j] for j in bad_idx])\n",
    "fpr_std, tpr_std, auc_std = uq.roc_curve_UQ_method_computation([stds[k] for k in good_idx], [stds[j] for j in bad_idx])\n",
    "fpr_std_tta, tpr_std_tta, auc_std_tta = uq.roc_curve_UQ_method_computation([stds_tta[k] for k in good_idx], [stds_tta[j] for j in bad_idx])\n",
    "fpr_combined, tpr_combined, auc_combined = uq.roc_curve_UQ_method_computation([max_values[k] for k in good_idx], [max_values[j] for j in bad_idx])\n",
    "\n",
    "uq.roc_curve_UQ_methods_plot(['Distance to hard labels', 'Standard deviation models ensembling', 'Standard deviation TTA', 'Method combination'], [fpr_distance_to_gstd, fpr_std, fpr_std_tta, fpr_combined], [tpr_distance_to_gstd, tpr_std, tpr_std_tta, tpr_combined], [auc_distance_to_gstd, auc_std, auc_std_tta, auc_combined])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_csv = r'/mnt/data/psteinmetz/neotex/CSV/BOUNDING_BOX.csv'\n",
    "path_to_csv_ville = r'/mnt/data/psteinmetz/neotex/CSV/Bounding_box_ville.csv'\n",
    "path_to_csv_ozgun = r'/mnt/data/psteinmetz/neotex/CSV/ThseOzgun-Kappa_OM_CM_DATA_2023-08-12_1625_relFF.csv'\n",
    "\n",
    "data_train = pd.concat((dt.fread(path_to_csv).to_pandas(), dt.fread(path_to_csv_ville).to_pandas()), ignore_index=True).dropna(axis=1)\n",
    "shape_target_train = pd.concat((data_train[['Record_ID']], data_train[['Shape.1']]), axis=1)\n",
    "shape_modified = shape_target_train.replace('Oval', 'Round')\n",
    "\n",
    "data_ozgun = dt.fread(path_to_csv_ozgun).to_pandas()\n",
    "data_ozgun = data_ozgun[['record_id', 'binaire_shape_exp']]#, 'binaire_shape_junior']]\n",
    "\n",
    "data_ozgun = data_ozgun.replace(True, 'Irregular')\n",
    "data_ozgun = data_ozgun.replace(False, 'Round')\n",
    "\n",
    "# Combine col1 and col2 into a new column 'combined' where values are equal, otherwise NaN\n",
    "#data_ozgun['combined'] = np.where(data_ozgun['binaire_shape_exp'] == data_ozgun['binaire_shape_junior'], data_ozgun['binaire_shape_exp'], np.nan)\n",
    "\n",
    "# Drop rows where 'combined' is NaN, but keep 'ID' and 'combined' columns\n",
    "#data_ozgun = data_ozgun[['record_id', 'combined']].dropna()\n",
    "shape_modified_ozgun = data_ozgun.rename(columns={\"record_id\": \"Record_ID\", \"binaire_shape_exp\": \"Shape.1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '/mnt/data/psteinmetz/neotex/data_CNN/images_15062024/'\n",
    "data = pd.concat(\n",
    "    (\n",
    "        pd.DataFrame(glob.glob(f'{images_path}*/*png')),\n",
    "        pd.DataFrame(\n",
    "            [x.split('/')[-1][:-4] for x in glob.glob(f'{images_path}*/*png')]\n",
    "        ),\n",
    "        pd.DataFrame(\n",
    "            [k.split('/')[-2] for k in glob.glob(f'{images_path}*/*png')]\n",
    "        ),\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "data.columns = ['Path', 'ID', 'Shape']\n",
    "data.set_index('ID', inplace=True)\n",
    "axialcuts_dataset = AxialCutsDataset(data_shape=data, downsample=True)\n",
    "\n",
    "path_to_csv = r'/mnt/data/psteinmetz/neotex/CSV/BOUNDING_BOX.csv'\n",
    "data_train = dt.fread(path_to_csv).to_pandas()\n",
    "shape_target_train = pd.concat((data_train[['Record_ID']], data_train[['Shape.1']]), axis=1)\n",
    "shape_modified_tr = shape_target_train.replace('Oval', 'Round')\n",
    "shape_modified_tr.set_index('Record_ID', inplace=True)\n",
    "list_cases, index = np.unique((pd.DataFrame(axialcuts_dataset.data.index)['ID'].apply(lambda x: x.split('_')[0])), return_index=True)\n",
    "X = list_cases\n",
    "y = np.array(shape_modified_tr['Shape.1'])\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path_eval_tr = '/mnt/data/psteinmetz/neotex/data_CNN/model_evaluation/evaluation_training_db'\n",
    "data_eval_tr = pd.concat(\n",
    "    (\n",
    "        pd.DataFrame(glob.glob(f'{images_path_eval_tr}/*png')),\n",
    "        pd.DataFrame(\n",
    "            [x.split('/')[-1][:-4] for x in glob.glob(f'{images_path_eval_tr}/*png')]\n",
    "        ),\n",
    "        pd.DataFrame(\n",
    "            np.zeros(len(glob.glob(f'{images_path_eval_tr}/*png')))\n",
    "        ),\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "data_eval_tr.columns = ['Path', 'ID', 'Shape']\n",
    "data_eval_tr.set_index('ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_cv = []\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    ids_tr = pd.DataFrame(data_eval_tr.index)['ID'].apply(lambda x: x.split('_')[0]).astype('int')\n",
    "    index_positions = ids_tr[ids_tr[:].isin(np.sort(ids_tr[:].unique())[test_index])].index\n",
    "    axialcuts_dataset_eval_tr = AxialCutsDataset(data_shape=data_eval_tr.iloc[index_positions], downsample=False, transform=data_transforms)\n",
    "    eval_all_data_tr = DataLoader(axialcuts_dataset_eval_tr, num_workers=12)\n",
    "    \n",
    "    # Store results\n",
    "    all_results = []\n",
    "    mean_pred = []\n",
    "    true_labels = []\n",
    "    names = []\n",
    "    model = [models_list[i].to(device)]\n",
    "    # Inference\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_all_data_tr:\n",
    "            images = batch['image']\n",
    "            labels = batch['shape']\n",
    "            img_names = batch['name']\n",
    "            pred_probs = predict(model, images)\n",
    "            \n",
    "            # Collect the results\n",
    "            mean_pred.append(np.mean(pred_probs))\n",
    "            true_labels.append(labels.item())\n",
    "            all_results.append({\n",
    "                'img_name': img_names[0],\n",
    "                'true_label': labels.item(),\n",
    "                'predicted_probabilities': pred_probs,\n",
    "                'predicted_class': int(np.mean(pred_probs) > 0.5),\n",
    "                'std': np.std(pred_probs),\n",
    "                'mean': np.mean(pred_probs)\n",
    "            })\n",
    "    results_cv.append(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tumor_predictions_with_percentages(results_cv[4], shape_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, bal_acc, sensitivity, specificity = classify_tumors_by_contingent_blocks_with_sorting(results_cv[0], shape_modified)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Balanced Accuracy:\", bal_acc)\n",
    "print(\"Sensitivity (Irregular):\", sensitivity)\n",
    "print(\"Specificity (Round):\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "all_results_tr = []\n",
    "mean_pred = []\n",
    "true_labels = []\n",
    "names = []\n",
    "models = [model.to(device) for model in models_list]\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    for batch in eval_all_data:\n",
    "        images = batch['image']\n",
    "        labels = batch['shape']\n",
    "        img_names = batch['name']\n",
    "        pred_probs = predict(models, images)\n",
    "        \n",
    "        # Collect the results\n",
    "        mean_pred.append(np.mean(pred_probs))\n",
    "        true_labels.append(labels.item())\n",
    "        all_results_tr.append({\n",
    "            'img_name': img_names[0],\n",
    "            'true_label': labels.item(),\n",
    "            'predicted_probabilities': pred_probs,\n",
    "            'predicted_class': int(np.mean(pred_probs) > 0.5),\n",
    "            'std': np.std(pred_probs),\n",
    "            'mean': np.mean(pred_probs)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tumor_predictions_with_percentages(all_results_tr, shape_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_tr, bal_acc_tr, sensitivity_tr, specificity_tr = classify_tumors_by_contingent_blocks_with_sorting(all_results_tr, shape_modified)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm_tr)\n",
    "print(\"Balanced Accuracy:\", bal_acc_tr)\n",
    "print(\"Sensitivity (Irregular):\", sensitivity_tr)\n",
    "print(\"Specificity (Round):\", specificity_tr)\n",
    "display_confusion_matrix(cm_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path_eval_ozgun = '/mnt/data/psteinmetz/neotex/data_CNN/model_evaluation/evaluation_Ozgun/'\n",
    "data_eval_ozgun = pd.concat(\n",
    "    (\n",
    "        pd.DataFrame(glob.glob(f'{images_path_eval_ozgun}/*png')),\n",
    "        pd.DataFrame(\n",
    "            [x.split('/')[-1][:-4] for x in glob.glob(f'{images_path_eval_ozgun}/*png')]\n",
    "        ),\n",
    "        pd.DataFrame(\n",
    "            np.zeros(len(glob.glob(f'{images_path_eval_ozgun}/*png')))\n",
    "        ),\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "data_eval_ozgun.columns = ['Path', 'ID', 'Shape']\n",
    "data_eval_ozgun.set_index('ID', inplace=True)\n",
    "\n",
    "\n",
    "axialcuts_dataset_eval_ozgun = AxialCutsDataset(data_shape=data_eval_ozgun, downsample=False, transform=data_transforms)\n",
    "eval_all_data_ozgun = DataLoader(axialcuts_dataset_eval_ozgun, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "all_results_oz = []\n",
    "mean_pred = []\n",
    "true_labels = []\n",
    "names = []\n",
    "models = [model.to(device) for model in models_list]\n",
    "# Inference\n",
    "with torch.no_grad():\n",
    "    for batch in eval_all_data_ozgun:\n",
    "        images = batch['image']\n",
    "        labels = batch['shape']\n",
    "        img_names = batch['name']\n",
    "        pred_probs = predict(models, images)\n",
    "        \n",
    "        # Collect the results\n",
    "        mean_pred.append(np.mean(pred_probs))\n",
    "        true_labels.append(labels.item())\n",
    "        all_results_oz.append({\n",
    "            'img_name': img_names[0],\n",
    "            'true_label': labels.item(),\n",
    "            'predicted_probabilities': pred_probs,\n",
    "            'predicted_class': int(np.mean(pred_probs) > 0.5),\n",
    "            'std': np.std(pred_probs),\n",
    "            'mean': np.mean(pred_probs)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tumor_predictions_with_percentages(all_results_oz, shape_modified_ozgun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_oz, bal_acc_oz, sensitivity_oz, specificity_oz = classify_tumors_by_contingent_blocks_with_sorting(all_results_oz, shape_modified_ozgun)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm_oz)\n",
    "print(\"Balanced Accuracy:\", bal_acc_oz)\n",
    "print(\"Sensitivity (Irregular):\", sensitivity_oz)\n",
    "print(\"Specificity (Round):\", specificity_oz)\n",
    "display_confusion_matrix(cm_oz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, bal_acc, sensitivity, specificity = classify_tumors_by_contingent_blocks_with_sorting(all_results_tr + all_results_oz, pd.concat((shape_modified, shape_modified_ozgun)))\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"Balanced Accuracy:\", bal_acc)\n",
    "print(\"Sensitivity (Irregular):\", sensitivity)\n",
    "print(\"Specificity (Round):\", specificity)\n",
    "display_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
